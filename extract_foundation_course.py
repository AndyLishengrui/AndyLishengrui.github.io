#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å»ºç«‹æ ¹åŸºè¯¾ç¨‹æ•°æ®æå–è„šæœ¬
ä»Wordå¯¼å‡ºçš„HTMLä¸­æå–è¯¾ç¨‹ç»“æ„å’Œå†…å®¹
"""

from bs4 import BeautifulSoup
import json
import re

# 12è¯¾çš„å‡†ç¡®æ ‡é¢˜
LESSON_TITLES = [
    "ç½ªä¸å¾—æ•‘",
    "ä¸»æƒä¸é¡ºæœ",
    "æ‚”æ”¹ä¸æ´—ç¤¼",
    "åœ£çµä¸å±çµæ©èµ",
    "æ¸´æ…•ä¸ç¥çš„è¯è¯­",
    "é—¨å¾’ä¸å¸¦é¢†",
    "å±çµå®¶åº­ä¸æ•™ä¼šç”Ÿæ´»",
    "ç¥·å‘Šä¸æ•¬æ‹œ",
    "ä¿¡å¿ƒä¸ç›¼æœ›",
    "å¯Œè¶³ä¸æ…·æ…¨",
    "ä¼ ç¦éŸ³ä¸ä¸–ç•Œå®£æ•™",
    "å¤æ´»ä¸å®¡åˆ¤"
]

def extract_foundation_course():
    """æå–å»ºç«‹æ ¹åŸºè¯¾ç¨‹çš„ç»“æ„å’Œå†…å®¹"""
    
    print("ğŸ“š å¼€å§‹è§£æå»ºç«‹æ ¹åŸºè¯¾ç¨‹...")
    
    # è¯»å–HTMLæ–‡ä»¶
    with open('å»ºç«‹æ ¹åŸº.html', 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # è·å–æ‰€æœ‰æ–‡æœ¬æ®µè½
    paragraphs = soup.find_all('p')
    
    # è¯¾ç¨‹ç»“æ„
    courses = []
    lesson_starts = {}  # è®°å½•æ¯è¯¾çš„å¼€å§‹ä½ç½®
    
    print(f"æ‰¾åˆ° {len(paragraphs)} ä¸ªæ®µè½")
    print("\nğŸ“– ç¬¬ä¸€æ­¥ï¼šå®šä½12è¯¾ä½ç½®...")
    
    # å…ˆæ‰¾åˆ°æ¯è¯¾çš„å¤§æ ‡é¢˜ä½ç½®
    for i, p in enumerate(paragraphs):
        text = p.get_text().strip()
        for lesson_num, title in enumerate(LESSON_TITLES, 1):
            # æŸ¥æ‰¾å¤§æ ‡é¢˜ï¼ˆfont-size: 24.0pt æˆ–æ›´å¤§çš„ï¼Œä¸”æ–‡æœ¬è¾ƒçŸ­ï¼‰
            if title in text:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§å­—ä½“æ ·å¼
                html_str = str(p)
                if ('font-size:24.0pt' in html_str or 
                    'font-size:19.5pt' in html_str):
                    # ç¡®ä¿ä¸æ˜¯é¡µçœ‰é¡µè„šï¼ˆé€šå¸¸æ˜¯font-size:7.0ptæˆ–9.0ptï¼‰
                    if lesson_num not in lesson_starts:
                        lesson_starts[lesson_num] = i
                        print(f"  âœ“ ç¬¬{lesson_num}è¯¾ã€Š{title}ã€‹- ä½äºæ®µè½ {i}")
                    break
    
    print(f"\nğŸ“„ ç¬¬äºŒæ­¥ï¼šæå–æ¯è¯¾çš„å†…å®¹...")
    
    # ä¸ºæ¯è¯¾æå–å†…å®¹
    for lesson_num in range(1, 13):
        if lesson_num not in lesson_starts:
            continue
        
        lesson_title = LESSON_TITLES[lesson_num - 1]
        start_idx = lesson_starts[lesson_num]
        end_idx = lesson_starts.get(lesson_num + 1, len(paragraphs))
        
        print(f"\n  ç¬¬{lesson_num}è¯¾ã€Š{lesson_title}ã€‹")
        
        # æå–è¿™ä¸€è¯¾çš„æ‰€æœ‰æ®µè½
        lesson_paragraphs = paragraphs[start_idx:end_idx]
        
        # æå–èŠ‚å’Œé—®é¢˜
        sections = extract_sections(lesson_paragraphs, lesson_title)
        
        courses.append({
            'lesson': lesson_num,
            'title': lesson_title,
            'sections': sections
        })
        
        print(f"    âœ“ æ‰¾åˆ° {len(sections)} ä¸ªèŠ‚")
    
    print(f"\nâœ… è§£æå®Œæˆï¼å…±æ‰¾åˆ° {len(courses)} è¯¾")
    
    # ä¿å­˜ä¸ºJSON
    output_file = 'data/foundation_course.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({'courses': courses}, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {output_file}")
    
    return courses

def extract_sections(paragraphs, lesson_title):
    """ä»æ®µè½ä¸­æå–èŠ‚çš„å†…å®¹"""
    sections = []
    current_section = None
    current_content = []
    current_question_num = 0
    
    section_pattern = re.compile(r'ç¬¬([ä¸€äºŒä¸‰å››äº”])èŠ‚')
    
    for p in paragraphs:
        text = p.get_text().strip()
        
        if not text or len(text) < 2:
            continue
        
        # æ£€æµ‹èŠ‚æ ‡é¢˜
        section_match = section_pattern.search(text)
        if section_match:
            # ä¿å­˜ä¸Šä¸€èŠ‚
            if current_section:
                current_section['content'] = '\n'.join(current_content)
                sections.append(current_section)
            
            # å¼€å§‹æ–°èŠ‚
            section_num = convert_chinese_number(section_match.group(1))
            current_section = {
                'section': section_num,
                'title': text.replace(lesson_title, '').strip(),
                'questions': []
            }
            current_content = []
            current_question_num = 0
            continue
        
        if current_section:
            # æ£€æµ‹é—®é¢˜ï¼ˆä»¥æ•°å­—å¼€å¤´ï¼‰
            question_match = re.match(r'^(\d+)\.\s*(.+)', text)
            if question_match:
                current_question_num = int(question_match.group(1))
                question_text = question_match.group(2)
                
                # ä¸‹ä¸€è¡Œå¯èƒ½æ˜¯ç»æ–‡å¼•ç”¨
                current_question = {
                    'num': current_question_num,
                    'question': question_text,
                    'scripture_ref': None,
                    'answer_lines': 0,
                    'is_personal': 'ä¸ªäººåº”ç”¨' in question_text or 'åº”ç”¨é¢˜' in question_text
                }
                current_section['questions'].append(current_question)
            
            # æ£€æµ‹ç»æ–‡å¼•ç”¨ï¼ˆçŸ­æ–‡æœ¬ï¼ŒåŒ…å«æ•°å­—å’Œå†’å·ï¼‰
            elif current_question_num > 0 and re.match(r'^[\u4e00-\u9fa5]{1,5}\s*\d+:\d+', text):
                if current_section['questions']:
                    current_section['questions'][-1]['scripture_ref'] = text
            
            # è®¡ç®—ç­”æ¡ˆè¡Œæ•°ï¼ˆä¸‹åˆ’çº¿ï¼‰
            elif '_' * 20 in text:
                if current_section['questions']:
                    current_section['questions'][-1]['answer_lines'] += 1
            
            # æ™®é€šå†…å®¹
            else:
                current_content.append(text)
    
    # ä¿å­˜æœ€åä¸€èŠ‚
    if current_section:
        current_section['content'] = '\n'.join(current_content)
        sections.append(current_section)
    
    return sections

def convert_chinese_number(chinese_num):
    """è½¬æ¢ä¸­æ–‡æ•°å­—ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—"""
    chinese_to_arabic = {
        'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
        'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
        'åä¸€': 11, 'åäºŒ': 12
    }
    
    if isinstance(chinese_num, str) and chinese_num.isdigit():
        return int(chinese_num)
    
    return chinese_to_arabic.get(chinese_num, 0)

def generate_course_summary(courses):
    """ç”Ÿæˆè¯¾ç¨‹æ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“š å»ºç«‹æ ¹åŸºè¯¾ç¨‹ç»“æ„æ€»ç»“")
    print("="*60)
    
    for course in courses:
        print(f"\nç¬¬{course['lesson']}è¯¾: {course['title']}")
        for section in course['sections']:
            questions = section.get('questions', [])
            personal_q = len([q for q in questions if q.get('is_personal', False)])
            scripture_q = len([q for q in questions if not q.get('is_personal', False)])
            print(f"  ç¬¬{section['section']}èŠ‚: {scripture_q} ç»æ–‡é¢˜ + {personal_q} åº”ç”¨é¢˜")
    
    total_sections = sum(len(c['sections']) for c in courses)
    total_questions = sum(
        sum(len(s['questions']) for s in c['sections'])
        for c in courses
    )
    
    print(f"\nğŸ“Š æ€»è®¡:")
    print(f"  è¯¾ç¨‹æ•°: {len(courses)}")
    print(f"  èŠ‚æ•°: {total_sections}")
    print(f"  é—®é¢˜æ•°: {total_questions}")

if __name__ == "__main__":
    courses = extract_foundation_course()
    generate_course_summary(courses)